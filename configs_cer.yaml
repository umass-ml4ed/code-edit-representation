##################################################
# exp_opts
##################################################
seed: 0
exp_name: 'cer' 
use_neptune: true
save_model: false
testing: false # only use a very small portion of the dataset for testing purposes
neptune_project: 'hhjami/Code-Edit-Representation' # change to your own "username/projectname"
log_train_every_itr: 100
model_save_dir: 'checkpoints'
use_cuda: true
verbose: true
##################################################
# data_opts
##################################################
data_path: 'data'
test_size: 0.2 # percentage of test dataset
max_len: 200 # maximum number of submission per student 
true_false_ratio: 1 # ratio of false to true samples, multiplier of the number of true
##################################################
# model_opts
##################################################
# model_name: 't5-base'
model_inp_dim: 768 # Fixed at 768 as it's the output dimension of t5-base, codet5-base
# model_name: 't5-large'
# model_inp_dim: 1024 # Fixed at 1024 as it's the output dimension of t5-large
model_name: 'Salesforce/codet5-base'
##################################################
# train_generator_opts
##################################################
epochs: 20
batch_size: 12
lr: 1e-5
lr_pretrained_encoder: 1e-8
lr_fc_edit_encoder: 1e-5
lr_fc_classifier: 1e-5
use_scheduler: true
warmup_ratio: 0.1
loss_fn: 'ContrastiveLoss' # 'BCEWithLogitsLoss' or 'ContrastiveLoss'
margin: .25
accumulation_steps: 1
